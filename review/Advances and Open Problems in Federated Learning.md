## 出处

Advances and Open Problems in Federated Learning. 

arXiv:1912.04977v1 [cs.LG] 10 Dec 2019

## 目的

本文是一篇综述，介绍联邦学习，讨论FL最近的发展，并提出了广泛的开放问题和挑战。

## 背景

- 目标：在保证数据隐私安全及合法合规的基础上，实现共同建模，提升AI模型的效果。
- 体现集中数据收集和最小化的原则，解决在越来越注重隐私保护的情况下如何更好地训练模型。

- 解耦了机器学习训练与数据云存储的要求，使得客户数据本地存储，在合作训练模型的同时大大降低隐私风险。

## 结论

- 联邦学习指的是分布式客户端设备协作学习共享的预测模型，同时将所有训练数据保留在设备上。
- 无论是在工业界还是在学术界，该主题的兴趣都呈爆炸性增长，主要目的是使用联邦学习来解决各个行业中的隐私和数据收集挑战。
- 联邦学习正在广泛的跨学科领域中获得关注：从机器学习到优化到信息理论和统计再到密码学，公平性和隐私性以及鲁棒性，存在需要开放性问题和挑战需要我们关注。

## 主要内容

### 概念

1. 什么是联邦学习？

   联邦学习是一种机器学习设定，其中许多客户端（如移动设备或整个组织）在**中央服务器的协调下共同训练模型**，同时**保持训练数据的去中心化和分散性。**

   本质：联邦学习本质上是一种**分布式**机器学习技术，或机器学习**框架**。

   关键词（特点）：松散联邦的参与设备，中央服务器协调，<u>数据的不平衡，数据非独立同分布，设备的不可靠性，有限通信带宽</u>

   扩展的定义：每个设备的原始数据本地存储不交换转移，传递的是各个设备的重点更新focused update（对学习任务有着的最小必要信息），在中央服务器上通过聚合来实现模型的学习。

2. 联邦学习的研究意义

   FL为“使用中央服务器**从本地数据中学习但保持隐私性**”这样的特征、约束、限制的机器学习任务**提供了一种简写**，**特定解决这种问题**。（分散数据的隐私至上）

3. 联邦学习设置的分类

   根据不同场景可以分为两大类：“**跨设备**”和“**跨孤岛**”。

   跨设备：Gboard移动键盘；特征一致（任务一样），通过不同用户去训练得到特征

   跨孤岛cross-silo：医疗数据联邦学习；用户一致，通过不同任务去训练得到不同的样本

   |          | 跨孤岛                               | 跨设备                                       |
   | -------- | ------------------------------------ | -------------------------------------------- |
   | 客户端   | 不同的组织（医疗或金融）             | 移动设备或物联网设备                         |
   | 节点数量 | 2~100                                | 1~10^10                                      |
   | 节点状态 | 几乎稳定运行都可用                   | 大部分节点不在线，不稳定                     |
   | 主要瓶颈 | 计算瓶颈和通信瓶颈                   | 通信瓶颈(WiFi或更低速)，设备不在线           |
   | 参与次数 | 每个客户端都可参与每轮计算，携带状态 | 每个客户端可能只在任务中参与一次，全新无状态 |
   | 可靠性   | 几乎很少失败                         | 大多失败，设备状态变化不停，计算失败或退出   |

   

   > 补充：
   >
   > 不同用户但相同特征：水平的，许多用户排列在一块，按照用户不同划分数据
   >
   > 同一用户但不同特征：垂直的，对于一个用户可能去不同的场景办理不同的业务（任务），所以特征不同
   >
   > 我们把每个参与共同建模的企业称为参与方，根据多参与方之间数据分布的不同，把联邦学习分为三类：**横向联邦学习（跨设备/跨孤岛）、纵向联邦学习（跨孤岛）和联邦迁移学习。**
   >
   > <img src="https://pic3.zhimg.com/v2-2f90ef909f950e2e83e5bd9aad4f5432_r.jpg" alt="preview" style="zoom:80%;" />

   

4. 联邦学习的生命周期（训练模型）：完成一个**联邦学习任务**需要经历的过程

   > 问题确定 - 客户工具（预建立客户数据）- 仿真模型（使用代理数据设计模型原型测试学习超参数）- **联邦模型训练**（执行FL训练任务来训练模型的不同变体或不同超参数）- [联邦]模型评估（训练足够后分析模型选择好的候选）- 部署（选择好的模型后启动模型并实时A/B测试）
   >
   > 
   >
   > 挑战：如何让这个过程尽可能简单，并像集中训练的机器学习系统那般易用

<img src="Advances%20and%20Open%20Problems%20in%20Federated%20Learning.assets/image-20210113173523774.png" alt="image-20210113173523774" style="zoom:50%;" />

5. 联邦模型训练过程是怎样的？

   训练过程对用户来说应该是不可见的，不应影响用户体验；同时训练时的模型也不可见，部署阶段再对新模型进行用户可见

   > 客户端选择 - 广播 - 客户端计算 - **聚合** - 模型更新
   >
   > 选择合适的客户端 - 从服务器上下载模型和训练程序 - 客户端执行程序在本地计算出模型的更新 - 服务器聚合该轮所有参与设备的更新 - 服务器基于聚合更新来更新共享模型

   *【以FL中经典的优化算法**联邦平均算法FedAvg**介绍训练过程】*

   - 客户端运行SGD的一些步骤，在本地数据上进行计算
   - 服务器聚合采用的是对更新的本地模型进行求和取平均，然后形成更新的全局模型
   - 总结：联邦平均算法在每一轮对客户端随机抽样的子集应用局部SGD，并提出一个具体的更新加权方案

   <img src="Advances%20and%20Open%20Problems%20in%20Federated%20Learning.assets/image-20210119102358576.png" alt="image-20210119102358576" style="zoom:50%;" />

6. 联邦学习和完全去中心化学习（点对点分布式）的主要区别？

   > 联邦学习本质上也是一种分布式机器学习技术，其中<u>分布式有数据集中的和数据去中心化的</u>
   >
   > 此处对两个典型的分布式进行分析对比

   

   > FL服务器所导致的瓶颈问题，是中心成员更可能导致失败
   >
   > 引入“去中心化”：通过单个客户端之间的对等通信来代替与服务器的通信

   |          | 联邦学习                                                     | 去中心化（点对点）分布式                       |
   | -------- | ------------------------------------------------------------ | ---------------------------------------------- |
   | 编排方式 | 中央编排服务器或服务 **负责组织**训练，**但看不到原始数据**  | 没有集中的编排                                 |
   | 宽域通信 | **中心辐射拓扑（星型**），各个客户端通过分支连接到中心服务器 | **对等拓扑**（只是客户端之间连接），动态连接图 |

7. 数据集中式分布式学习与跨孤岛/跨设备联邦学习的综合对比？

   |                | 数据集中式的分布式学习                                       | 跨孤岛的联邦学习                                             | 跨设备的联邦学习                                             |
   | -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
   | 设置           | 在大量但扁平的数据上训练模型；客户端是计算节点               | 在数据孤岛上训练模型；客户端是不同的组织                     | 在各自数据上训练模型；客户端是大量的移动设备或物联网设备     |
   | 数据分布       | **数据集中存储**，并**能在客户端间混洗和平衡**；任何客户端都可以读数据集的任何部分 | **数据本地生成并保持去中心化(分散化)**；每个客户端存储各自数据且不能阅读其他客户端数据；<u>数据非独立或同分布</u> | 与跨孤岛一样                                                 |
   | 编排           | 集中编排（中央式编排）                                       | 中央编排服务器或服务 **负责组织编排**，**但从未看到原始数据** | 与跨孤岛一样                                                 |
   | 宽域通信       | 无（在一个数据中心/群集中完全连接客户端）                    | **中心辐射拓扑（星型**），各个客户端通过分支连接到中心服务器 | 与跨孤岛一样                                                 |
   | 数据可用性     | 所有客户端都是可用的                                         | 所有客户端都是可用的                                         | 在任何时候，<u>只有一小部分客户可用</u>，通常会有日间或其他变化。 |
   | 数据分布规模   | 通常1-1000个客户端                                           | 通常2-100个客户端                                            | 大规模并行，最多可达10^10                                    |
   | 主要瓶颈       | 计算（假设网络很快）                                         | 计算或者通信                                                 | 主要是通信，跨设备往往使用wifi或更慢连接                     |
   | 可寻址性       | 每个客户端有一个标识或名称允许系统访问                       | 与数据集中相同                                               | 不能对客户端建立索引                                         |
   | 客户端有状态性 | 有状态的，每个客户端都可以<u>参与到计算的每一轮中</u>，不断地传递状态。 | 与数据集中相同                                               | <u>无状态，每个客户端只能在任务中参与一次</u>，每轮计算都有未见过的新客户样本 |
   | 客户端可靠性   | 相对较少的失败次数                                           | 与数据集中相同                                               | 高度不可靠性，在每轮计算中参与的<u>不少客户端都可能失败或退出</u>（容易变得不合格） |
   | 数据分区轴     | 数据可以在客户端之间<u>任意分区/重新分区</u>。               | <u>固定分区</u>。能够根据**样本分区（横向）**或者**特征分区（纵向**） | 根据**样本固定分区（横向）**                                 |

   

8. 挑战：**激励机制**

   >  对于忠实参与者来说很重要，尤其是在跨孤岛设置中，参与方可能也是商业竞争对手

   目标：如何分配收益给贡献者来维持长期参与；考虑那些提供防御对抗性数据的用户，增强系统安全性；优化参与者的参与度来提高系统效率

---

### 效率和效用

1. 联邦学习的主要挑战

   - non-IID和不平衡的数据
   - 有限的通信带宽
   - 不可靠和有限的可用设备

2. 什么是non-IID非独立同分布数据？

   > 特征x标签y的监督学习任务，联邦学习的统计模型涉及到两个层面的采样：
   >
   > ① 对客户端$i \sim Q$进行采样，得到在**可用客户端上的数据分布**
   >
   > ② 对**客户端本地数据分布**进行采样$(x,y) \sim \mathcal{P}_i(x,y)$
   >
   > 联邦学习中的non-IID通常指的是客户端$i$和客户端$j$所对应的$\mathcal{P}_i$与$\mathcal{P}_j$不同，同时$\mathcal{Q}$和$\mathcal{P_i}$是可能随着时间的推移而改变。【两个维度：不同客户端数据的，以及客户端总体服从的分布】

   - **不同客户端数据分布不同** $(x,y) \sim \mathcal{P}_i(x,y)\not= P_j$
     - **特征分布倾斜**：$\mathcal{P}(y|x)$相同，$\mathcal{P}_i(x)$不同；不同人的笔迹不同*【尽管不同客户端基于某特征所预测出来的结果(分布)是一样的 ，但是单独考虑这个特征时，各自关于该特征分布是不同的-倾斜】*
     - **标签分布倾斜**：$\mathcal{P}(x|y)$相同，$\mathcal{P}(y)$不同；企鹅在只在南极、北极熊只在北极*【尽管不同客户端根据某结果反推某特征的概率(分布 先验概率)是一样的，但是单独考虑这个结果时各自客户端的分布是不同的-倾斜】*
     - **标签相同特征不同**：$\mathcal{P}(y)$相同，$\mathcal{P}(x|y)$不同；概念飘移，表达再见不同地区有不同的方式*【即使最终预测的结果是相同的，但是可能各个客户端的关于某特征的条件概率(分布)不同】*
     - **特征相同标签不同**：$\mathcal{P}_i(x)$相同，$\mathcal{P}(y|x)$不同；点头表示Yes / No?*【同样的特征分布，但是在不同的客户端里基于该特征得到的预测结果不一样】*
     - **数量不平衡**：不同的客户拥有数据的数量差异可能很大。
   - **违反独立性**：训练过程中，只要概率分布$\mathcal{Q}$（可用客户端）发生变化，就会其导致违反独立性。*【比如跨设备中设备一般在晚上满足训练要求才能参与，此时可用节点大多在附近的时区（地理位置）】*
   - **数据集偏移**：训练集测试集不同分布*【分布$\mathcal{Q}$和$\mathcal{P}$对于时间的依赖性可能引入传统意义上的数据集偏移】*

3. 处理non-IID数据的方法

   - 修改原有算法或探索新算法，为non-IID数据构造一个全局模型

   - 添加一些数据让客户端之间non-IID的数据变得更加相似，如创建一个全局共享的小数据集

   - 将它作为每个客户端的一个特征（尽可能降低它的影响），每个客户端有各自定制的模型

     > 此时模型的聚合不再是一般的联邦学习模型的聚合（要求使用同一个全局模型），相当于蒸馏。
     >
     > 本地小模型可以帮助公共模型提升性能，公共模型也可以给小模型提供性能，<u>互相传递知识</u>，但是最终聚合的是大家都一样的公共模型，只是我本地还有个小模型存在（<u>保证公共模型可以聚合，同时本地有自己的模型</u>）——可以参考deep mutual learning

4. 联邦学习的优化算法有什么理论分析成果？

   - 讨论IID（独立同分布）的情况：

     **客户端每个mini-batch与整个训练数据集分布相同**，定义随机优化问题： $$ \min\limits_{x\in\mathbb{R}}F(x):=\mathop{\mathbb{E}}\limits_{z\thicksim \mathcal{P}}[f(x;z)] $$ 对 $f$ 的不同假设会产生不同的保证。（最小化损失函数=最小化在某个训练集上的经验风险）

     - 如果 $f$ 是凸的：

       假设$H-smooth$: 对于任意$x,y$，有 $$ ||\bigtriangledown f(x,z)-\bigtriangledown f(y,z)|| \leq H||x-y|| $$ 

       设置梯度bound：每次更新的梯度差值有个界限，不能太离谱： $$ \mathop{\mathbb{E}}\limits_{z\thicksim P}||\bigtriangledown_x f(x;z)-\bigtriangledown F(x)|| \leq \sigma^2 $$    

       **Baseline1：**（<u>服务器角度</u>看底下这么多/M个客户端训练的如何）考虑$M$个客户端，每个客户端分别计算$K$个mini-batch上的梯度： $$ \mathcal{O}\left(\frac{H}{T^{2}}+\frac{\sigma}{\sqrt{T K M}}\right) $$ 

       **Baseline2：**（<u>某个客户端的角度</u>看联邦学习和普通的相比训练的如何）考虑1个客户端，连续执行$KT$步： $$ \mathcal{O}\left(\frac{H}{(T K)^{2}}+\frac{\sigma}{\sqrt{T K}}\right) $$ 

       最优“统计”项$(\sigma / \sqrt{T K M})$：可以认为是随机带来的干扰项，*如σ越小越接近真实梯度则干扰越小；M客户端个数越多样本数据越多效果越好，这个值越小也就是干扰小……*

       最优“优化”项$(H/ \sqrt{(HK)^2})$：可以认为是优化本身的收敛率

     - 如果 $f$ 是非凸的：

       

   - 讨论Non-IID（非独立同分布）的情况：

     $N$个客户端都拥有自己的本地数据分布$\mathcal{P}*i$和本地目标函数： $$ f*{i}(x)=\underset{z \sim \mathcal{P}*{i}}{\mathbb{E}}[f(x ; z)] $$ ，其中$f(x;z)$为模型$x$对于样本$z$的损失。

     我们通常希望最小化： $$ F(x)=\frac{1}{N} \sum*{i=1}^{N} f_{i}(x) $$ ，请注意，当$\mathcal{P}_i$是同分布的时候就是IID的设定。

   

5. 有哪些多模型方法？（推断时为不同的客户有效地使用不同的模型）

   - 特征个性化：在<u>全局模型中添加特征的输入</u>（上下文信息），可以实现不同用户使用不同的模型（参数）的个性化功能
   - 多任务学习：考虑<u>客户端（本地数据集）和学习任务（待训练模型）的关系</u>，<u>将每个客户端本地数据看成一个单独的任务</u>，而不是认为它们只是一部分分离的数据（相对于总数据而言），可以实现训练后对每个任务一个模型，
   - 本地微调和元学习：（1）用<u>联邦学习训练单一模型</u>，然后将模型部署到所有客户端，在进行<u>推断之前基于本地数据进行个性化的附加训练</u>实现个性化；（2）标准的LTL设置中，在任务上有一个元分布，从中提取样本来学习算法

6. 联邦学习的通信瓶颈有哪些？

   不同的联邦学习场景通信约束有不同的特点

   - 跨设备：WiFi速度慢、设备不在线
   - 跨孤岛：上传速度通常慢于下载速度，中心节点带宽限制

   可研究方向：精确性和通信量之间的基本平衡

7. 联邦学习的通信瓶颈有什么解决思路？

   目前解决方法主要有**通信内容压缩（减少通信量）**和**FPGA通信加速（降低通信延迟）**两种思路

8. 通信内容压缩有哪些分类？

   根据*压缩目标的不同*，可以大致分为3类：

   - **梯度压缩（上传压缩）**：减少从<u>客户端到服务器</u>通信的对象的大小，该对象用于更新全局模型；
   - **模型广播压缩（下载压缩）**：减小从<u>服务器向客户端</u>广播的模型的大小，客户端从该模型开始本地训练；
   - **本地计算压缩（本地压缩）**：修改整体训练算法，使本地训练过程在计算上更加高效
   - 【补充】修改模型压缩：修改训练程序，使最终的模型更紧凑，或更有效地进行推理【现在难以采用】

9. 目前有哪些压缩方法

   - 量化方法：降低更新参数的“分辨率”，如：整数化，二值化
   - 低秩矩阵：将通信内容结构化，低秩分解
   - 稀疏化：只传递足够重要的信息
   - 知识蒸馏：将大模型知识迁移到小模型

11. 压缩方法还需考虑的开放问题？
    - 现有的不是为压缩或量化通信而设计的，<u>兼容考虑差分隐私和安全聚合</u>
    - <u>考虑无线干扰、噪声信道和信道波动</u>，实现降低模型训练延迟、增强可靠性。主要方法有：
      - 联邦蒸馏federated distillation (FD)：工人们交换模型输出参数而不是模型参数，优化工人调度策略
      - 利用无线信道的独特特性(如广播和叠加)作为自然数据聚合器：不同工作人员同时传输的模拟波叠加在服务器上，并由无线信道系数进行加权。
12. 将FL扩展到其他ML问题上
    - FL主要考虑监督学习任务
    - 另一类重要模型：描述其预测中的不确定性的模型，期望能够扩展到这类模型上
      - 大多数模型不能代表不确定性也不允许参数学习的概率解释，这推动了**贝叶斯模型**与深度学习相结合的工具和技术的最新发展
      - **贝叶斯神经网络**：对过拟合具有更强的鲁棒性，并且可以很容易地从小型数据集学习【概率分布、概率推理】
      - **人们期望贝叶斯方法为经典的联邦学习提供一个概念上的改进**



> 补充内容：FPGA

13. 什么是FPGA？

    CPU、GPU（通用芯片）、TPU、矿机(ASIC)、FPGA（半ASIC）

14. 为什么要用FPGA？

    FPGA适合通信领域，因为通信领域需要高速的通信协议处理，另一方面通信协议随时都在修改，不适合做成专门的芯片，所以需要能够灵活改变的功能的FPGA。

15. FPGA在联邦学习中有哪些用武之地？

    - 定制通讯协议并用FPGA加速（跨孤岛场景：减少中间商）
    - 加速计算
      - 加速知识蒸馏（前推）
      - 加速模型计算（反传）

---

### 保护用户数据隐私

1. 机器学习的工作流是什么样的？（同样适用于FL）

   用户交互**提供数据**，机器学习训练过程**从数据中提取人机交互模式（生成模型）**，机器学习工程师或分析师**分析训练的模型质量**，最终将**模型部署**到终端用户上来支持具体用户体验。

   <img src="Advances%20and%20Open%20Problems%20in%20Federated%20Learning.assets/image-20210113173523774.png" alt="image-20210113173523774" style="zoom:50%;" />

2. FL当前是如何保证用户的隐私？

   通过**数据最小化**为参与用户提供一定程度的隐私：<u>原始用户数据永远不会离开设备</u>，只有<u>模型的更新</u>(如梯度更新)被发送到中央服务器。

   与原始数据相比，这些模型更新更专注于手头的学习任务(它们严格不包含关于用户的额外信息，与原始数据相比，通常要少得多)，单个更新只需要由服务器短暂地保存。

   > 但仍然没有正式的隐私保障，可以通过其他的方法来获得隐私

3. FL有哪些需要提供保护的威胁模型？（不同敌对参与者的多种威胁模型）

   | 数据访问节点 | 参与者                                                      | 威胁模型                                                     |
   | ------------ | ----------------------------------------------------------- | ------------------------------------------------------------ |
   | 客户端       | 通过系统设计或破坏设备获得<u>客户端设备的最高访问权限者</u> | 恶意客户端可以**检查所参与轮次从服务器接收的全部消息**（包括模型迭代），并可以**篡改训练过程** *【按理说只能收到最终更新整合后的模型】*。老实但好奇的客户端可以检查从服务器接收的所有消息，但<u>不能篡改培训过程</u>。<br />在某些情况下，安全包围/TEEs等技术可能会限制此类攻击者的影响和信息可见性，从而削弱该模型威胁程度。 |
   | 服务器       | 通过系统设计或破坏设备获得<u>服务器的最高访问权限者</u>     | 恶意服务器可以**检查所有轮次发送到服务器的全部消息**（包括梯度更新），并可以**篡改训练过程**。老实但好奇的客户端可以检查发送到服务器的所有消息，但<u>不能篡改培训过程</u>。<br />在某些情况下，安全包围/TEEs等技术可能会限制此类攻击者的影响和信息可见性，从而削弱该模型威胁程度。 |
   | 输出模型     | 工程师或分析师                                              | 恶意分析师或模型工程师**可以访问系统的多组输出**，【能够接触到很多输出（多个轮次、多个高参数的），因此要决定显示哪些输出给他们】<br />例如，<u>使用不同超参数的多个训练运行的模型迭代序列</u>（接触到服务器的多种输出）。*该向这类参与者发布什么信息来检查*是一个重要的系统设计问题。 |
   | 部署模型     | 其他设备                                                    | 在跨设备联邦学习场景下，最终模型可能部署到数亿个设备上。**访问部分受损**的设备可能仍满足**黑盒模型**，而**访问完全受损**的设备可以认为是**白盒模型**。*【按理说只能白盒访问】* |

4. 联邦学习有哪些需要解决的隐私方面？

   > 联邦学习计算的目的是让分析师或工程师通过计算请求获得结果，可以看作是**对分布式客户机数据集上的函数*f*的评估**（通常是机器学习模型训练算法，但可能更简单，例如基本的数据统计）

   - f 是怎么计算的，以及在f的计算过程中，中间结果的信息流动是怎样的*【提前数据最小化、安全多方计算MPC、可信化执行环境TEEs】*
   - 计算了什么，传给f的是什么：f本身计算的结果会向分析师和其他设备保护多少关于参与者的信息*【隐私保护披露技术，特别是差分隐私DP】*
   - 考虑可验证性的问题（我认为实际是可靠性）：客户机或服务器能够向系统中的其他人证明自己完成命令且不泄露运行时潜在的隐私*【验证技术，包括远程认证和零知识证明】*

5. 安全计算有哪些技术？

   > 安全计算的目标：评估计算分散输入的**函数**，判断其是否**仅向预期各方显示计算结果，而不显示任何附加信息**（例如各方的输入或任何中间结果）

   | 技术                                           | 特征                                                         |
   | ---------------------------------------------- | ------------------------------------------------------------ |
   | 差分隐私DP（本地、中心、混编、聚合、混合模型） | **从包含某用户的数据集的输出分析中可以了解该用户的个人信息**的量化。<br />具有差分隐私的算法必然<u>包含一定数量的随机性或噪声</u>，可以对其进行调整以掩盖用户对输出的影响。 |
   | 安全多方计算MPC                                | 两个或多个参与者**协作**，**通过密码学模拟完全可信的第三方**，第三方满足：<br />计算所有参与者提供的输入的（共识）函数；向选定的部分参与者显示计算结果，同时任一方没有进一步学习。 |
   | 同态加密HE                                     | 允许一方在<u>不具有纯文本访问权限</u>的情况下，**不解密密文下对密文执行数学运算**，从而**计算出它们的数据**的函数。<br />使参与者计算函数值，同时保持值隐藏。尽管计算成本更高，任意复杂度的数据函数都可以通过这种方式计算（“完全同态加密”）。 |
   | 可信执行环境TEEs                               | 可信执行环境提供了**在远程计算机上可靠地运行代码的能力**，<u>即使不信任计算机的所有者/管理员</u>。<br />通过限制任何一方（包括管理员）的能力来实现的，可信执行环境具有一致性、完整性、可测量性的性质 |

   

6. 有哪些受关注的安全计算问题？

   > 虽然安全多方计算和可信执行环境为分布式隐私数据上的任何函数的保密计算问题提供了一般解决方案，但许多优化可以应用到某些特定功能中

   - 安全聚合Secure Aggregation
     - n个客户端和1个服务器，**每个客户端提交一个值**，这样**服务器**就可以**学习到客户端值的聚合函数**，通常是总和。（中间参数不会透露）
     - 现有文献大部分探索了在单服务器设置（通过成对加法遮蔽、通过阈值同态加密、通过一般安全多方计算），以及在多个非合谋服务器设置，也可使用可信执行环境。
   - 安全混编Secure Shuffling
     - n个客户端和1个服务器，**每个客户端提交一条或多条消息**，这样**服务器**只**从所有客户端学习一个无序的消息集合**（multiset），而不需要更多。【认为是<u>安全聚合的一个实例</u>，其中值是多集单例（消息），聚合操作为多集求和】
     - 除了消息本身包含的信息之外，服务器无法判断任一条消息的发送者
     - 通常在混合网络的背景下进行研究，也有在可信计算的背景下进行的研究
   - 隐私信息检索PIR：Private information retrieval
     - 服务器为客户端提供的功能，1v1。它使客户端能从服务器托管的数据库中下载条目，从而**服务器无法获得客户端下载的条目的任何信息**
     - MPC使其分类：基于计算的PIR cPIR（一方可以执行协议的整个服务器端），基于信息论的PIR itPIR（多个非共谋方执行协议的服务器端）
     - PIR适用性障碍：cPIR计算成本高，itPIR在工业场景上难以可信地实现非共谋方的设置

7. 用什么技术来实现隐私保护披露（多少保护多少披露）？

   量化和限制个人信息披露的最新模型是**差异隐私（DP）**，其目的是在<u>发布的模型中引入一定程度的不确定性</u>，以充分**掩盖任何个人用户的贡献**。

   差异隐私由隐私损失参数(*ε*,*δ*)量化，其中较小的(*ε*,*δ*)对应于隐私性增强。

   > 对于所有*S*⊆Range(*A*)，以及所有相邻数据集*D*和*D’*，如果满足下式，则称随机化算法*A*是(*ε*,*δ*)-差异隐私的：
   >
   > *P*(*A*(*D*) ∈*S*) ≤ *eε\****P*(*A*(*D’*) ∈*S*) + *δ*

8. 差分隐私中有哪些减少对数据管理员信任需求（减少可信方需求）的方法？

   > 在假设集中设置情况下，差分隐私<u>应用实现隐私所需的扰动之前</u>，**对原始数据的收集需要可信方执行**，通常我们希望减少对可信方需求。
   >
   > 在FL中通常编排服务器将充当DP机制的可信实现者，确保只将私有化的输出发布给模型工程师或分析师。

   - 本地差分隐私 Local DP

     - 让每个客户端在**共享数据之前优先对他们的数据应用一个差分隐私转化**，来实现<u>不需要可信集中服务器下的差分隐私</u>

     - LDP与DP的对比：前者部署涉及大量的客户机和表项，但后者可以从更小的数据集中提供高实用性。

       > *【在保持效用的同时实现LDP是很困难的，因此引出了以下两种DP，介于完全中心化和完全本地化的差分隐私模型（DP和LDP之间）*

   - 分布式差分隐私 Distributed DP

     - 引入背景：在不依赖可信的中心服务器的情况下恢复中心DP的一些实用性，介于DP和LDP之间
     - 客户端计算和编码一个最小报告，此报告通过安全计算函数并将输出供中央服务器访问，在服务器检查时该输出已满足不同隐私要求。

   - 混合差分隐私Hybrid DP

     - 根据用户的信任模型偏好（例如对管理员信任与否）来划分用户，从而组合多个信任模型。
     - 通过允许多个模型共存，混合模型机制可以从给定的用户基础获得更多的效用，相比DP和LDP。【用户可以选择更适合自己的机制而不是一刀切导致效率下降】

9. 什么是可验证性？在FL中又是怎样的？

   可验证性计算证明**它忠实地完全了应做的行为**（对数据执行了所需的行为），**同时不损坏数据的潜在隐私**。

   在FL中可验证性的目的有两个（服务器和客户端）：

   - 服务器忠实地完全预期行为：如聚合输入、显示输入消息或添加用于差异隐私的噪声
   - 客户端的输入和行为遵循协议规范：如输入属于一个确定的范围，或者数据是正确生成的密文

10. 在可验证性计算中有哪些技术可以进行验证？

    - 零知识证明ZKPs
      - 是一种密码原语，**证明方对验证方声明陈述**，验证方依赖于证明方所知道的秘密信息，但不对验证方泄露这些秘密
      - 三个性质：完整性（如果<u>陈述是真的</u>，证明者和验证者遵循协议，<u>验证者将接受证明</u>）、可靠性（如果<u>陈述是假的</u>，验证者遵循协议，<u>验证者将拒绝证明</u>）、零知识（如果<u>陈述是真的</u>，证明者遵循协议协议中，<u>验证者只会了解到陈述是真实的，不会从交互中了解到任何隐私信息</u>）。
      - 有不同的ZK构造，不同构造之间的显著区别是需要可信设置：**计算CRS**，使用应该保持隐藏的秘密来计算CRS，CRS用来保证证据的可靠性
      - 影响不同情况下适用性的另一个重要特性是，<u>生成证明是否需要证明者和验证者之间的交</u>互
        - 区分：非交互零知识证明（NIZK），该证明使验证者能够向验证者发送一条消息，且无需进一步通信。（发送完后不再进一步交流）*【简洁的非交互式零知识证明SNARKs是一种ZKP类型】*
        - 越来越多的实际应用使用非交互式零知识证明，主要是由区块链驱动。在FL中如何有效地使用交互式ZKP系统和非交互式ZKP仍然是一个具有挑战性的开放性问题
    - 可信执行环境和远程认证
      - TEEs能够证明和验证在其环境中运行的代码（二进制），提供完整性和可证明性
      - 远程认证允许验证者安全地测量远程硬件平台的内部状态，并可用于建立静态或动态信任源。TEEs支持基于硬件、软件、混合远程认证（都可以）
      - 在FL环境中，TEEs和远程认证<u>对于客户端能够有效地验证服务器上运行的关键功能可能特别有用</u>。
        - 安全聚合或混编可以在TEEs中运行，并为它们的输出提供不同的隐私保证。因此服务器随后对差异隐私数据应用的后处理逻辑可以在服务器上运行，并且对客户端保持不敏感
      - 同时远程认证<u>使服务器证明FL计算中涉及的客户端的特定要求</u>，例如无泄漏、不变性和不可中断性

---

【该部分等待后续完善】

11. 假定存在一个可信任的服务器，有哪些为对抗客户和/或分析师提供保护方面的开放问题和挑战？

    > 恶意客户端可以接触到模型迭代，恶意分析师可以接触到多个模型输出，因此要限制或消除从模型迭代或最终模型中可以了解到的关于用户的信息，可以在**FL的迭代训练过程中使用用户级差异隐私**



12. 假设存在一个有敌意的服务器，有哪些现有工作和挑战？



---

### 鲁棒性

1. 联邦学习可能遇到什么样的安全威胁？

   > 见上一节：FL有哪些需要提供保护的威胁模型？（不同敌对参与者的多种威胁模型）

2. 联邦学习环境下的敌人（攻击者）有哪些能力特征？（联邦学习中一些主要的攻击模式）

   | 特征         | 描述                                                         |
   | ------------ | ------------------------------------------------------------ |
   | **攻击向量** | **敌人发起攻击的方式。**（中毒/回避）<br />*数据中毒*： 敌人<u>修改</u>用来<u>训练的用户数据集</u><br />*模型更新中毒*：敌人<u>修改发送回服务器的模型更新</u>数据<br />*回避攻击*：敌人<u>改变推断阶段使用的数据</u> |
   | 模型检查     | **敌人是否能够观察到模型参数**<br />*黑箱*：对手在<u>攻击前和攻击时都没有能力观测到模型参数</u>。联邦学习环境中一般不是这种情况<br />*陈旧白箱*：对手只能<u>观测到一个陈旧的模型</u>。当对手可以接触到参加中间训练回合的客户时，这自然会在联邦环境中出现。<br />*白箱*：对手<u>有能力直接观测到模型参数</u> |
   | 参与者串通   | **多个敌人是否可以协同发起攻击**<br />*无串通*：参与者无法通过串通发起攻击<br />*Cross-update串通*：<u>过去的</u>客户端参与者可*<u>与未来的</u>*参与者协同<u>攻击全局模型在未来的更新</u>（整个模型更新期间相继发生）<br />Wthin-update串通*：<u>当前</u>客户端参与者可协同发起<u>对模型当前更新的攻击</u>（实时共谋） |
   | 参与率       | **在训练期间敌人能多久发动一次攻击**<br />在跨设备联邦环境中，一个恶意用户可能只能参与一个模型训练回合<br />在跨孤岛联邦环境中，一个敌人可能能持续参与模型的学习过程 |
   | 适应性       | **敌人是否能在攻击过程中修改攻击参数**（攻击目标的变化）<br />*静态*：敌人必须在攻击之初确定攻击参数且无法在发起攻击后更改。<br />*动态*：敌人能够在模型训练过程中修改攻击 |

3. 针对攻击的目标不同，攻击分为几类？

   - 非针对性攻击（模型降级攻击）：目标是<u>降低模型的全局精度或全面“摧毁”全局模型</u>

   - 针对性攻击（后门攻击）：目标是<u>改变模型对少数例子的行为</u>，同时保持<u>对所有其他例子的良好</u>的整体准确性

     > 如在一组“绿色汽车”的训练图像中添加一个小的视觉工件(后门)，以便让模型将这些图像标记为“鸟类”；之后可以利用这一点来发动简单的回避攻击，方法是在一辆绿色汽车的任意图像中添加相同的视觉效果，将其归类为“鸟”。
     >
     > 敌人的模型更新迫使训练过的模型在一小部分数据（所有绿色的汽车）上学习错误的映射。
     >
     > - 若对数据的某个特定特征进行了有针对性的攻击，而该特性恰好出现在所有评估示例中，则无意间变成了非针对性攻击（一种转换情况）

4. 如何防御模型更新中毒？

   - 非针对性模型中毒攻击
     - 其中一种重要的模型：拜占庭威胁模型，分布式系统中的故障可使系统产生任意输出。*【引申只要对手可以<u>导致分布式系统中的进程产生任意输出</u>，则说对该分布式系统中进程的敌对攻击是拜占庭式攻击】*
     - 针对无目标模型中毒攻击特别是拜占庭攻击的防御机制
       - ① 多重拜占庭弹性防御：用<u>对平均值的稳健估计取代了服务器上的平均步骤</u>，例如基于中值的聚合器、Krum和修剪平均值【还需检测在FL中的有效性】
       - ② 使用冗余和洗牌数据来减轻拜占庭式攻击，但假设要求服务器能直接访问数据，在FL中不适用。【需协调基于冗余的防御机制(可能增加通信成本)和联邦学习系统(旨在降低通信成本)】
   - 针对性模型中毒攻击
     - 即使是单发攻击也足以将后门引入模型，难以区分中毒模型和未收到目标攻击的模型，因此难以检测后门的存在
     - 现有后门攻击防御由于数据访问和训练控制原因在FL中都不可用。【之后可探索使用零知识证明来确保用户提交的更新属性是预先确定的属性，以及基于硬件认证的解决方案】
   - 考虑参与者串通下的防御
     - 如果**对手能够进行串通**，那模型更新中毒攻击的效率将大大提升，使得对手能够发动更高效、更难被检测的模型更新攻击。
     - 这种模式与黑客攻击密切相关，由于服务器无法查看客户端数据，因此在FL中检测sybil攻击可能要困难得多，研究表明FL很容易受到有针对性和无针对性的sybil攻击【需要考虑如何在不检查节点数据的前提下防御共谋或检测合谋对手】

5. 数据中毒和模型中毒有什么关系？

   - 数据中毒攻击是模型更新中毒攻击的特殊情况：由于<u>数据中毒攻击最终会导致客户端输出到服务器信息的更改</u>，从而导致模型更新中毒
   - <u>数据中毒攻击的强度可以会弱一些</u>，特别是在参与率较低的情况下
   - *理解这两种攻击类型之间的关系，尤其是它们与客户端数量之间的关系，将极大地帮助我们理解联邦学习中的威胁。*

6. 如何防御数据中毒攻击？

   > 对于非针对性数据中毒攻击，由于数据中毒会导致模型更新中毒，因此*上文的任何针对拜占庭式更新的防御措施都同时可用于防御数据中毒*。【需要考虑在FL中如何分析和改进这些方法：非IID数据和客户的不可靠性】

   专门为数据中毒攻击设计的**数据净化和网络修剪防御**通常依赖于“数据净化”方法，旨在移除中毒或其他异常数据。这两种方法都不能直接在联邦学习环境中工作，都需要访问客户端数据或者类似于客户端数据的其他数据*【如何在FL中使用这两种方法而不丢失隐私是一个待解决的问题，或者开发新的方法】*

   数据净化：最近开发了使用稳健统计的数据净化，能在少量异常值下保持鲁棒性，针对性和非针对性皆可使用

   修剪防御：不是移除异常数据，而是试图移除干净数据上不活动的激活单元；防御针对性攻击

7. 如何防御在推断阶段的回避攻击？

   回避攻击：小心操作输入模型的样本来绕过已部署的模型

   一种充分研究的回避攻击形式是**“对抗式攻击”**：是测试输入的扰动版本，如在图像和音频领域，对抗性的例子通常是通过在测试例子中加入范数有界的扰动来构建的。

8. 训练阶段攻击和推断阶段攻击有什么关系？

   在训练阶段的攻击，对手可能会破坏训练过程，从而制造或增强模型的推理时间漏洞

9. 如何实现在隐私保障方面的防御？

   使用差分隐私来防御：在训练或测试时加入随机噪声，以减少特定数据点的影响。

   - 防御模型更新中毒攻击
     - 服务提供者可以通过(1)对客户端模型更新实施一个规范约束(例如，通过剪切客户端更新)，(2)聚合剪切的更新，(3)向聚合添加高斯噪声来约束任何单个客户端对整个模型的贡献。
     - 防止对任何个人更新(或一小群恶意的个人)进行过度拟合，与差异隐私的训练相同
   - 防御数据中毒攻击
     - 数据中毒表示一些被攻击的训练实例可能会严重影响学习模型；因此要使学习算法具有差异私有性，从而提高鲁棒性来抵制。有防止数据中毒攻击的差分隐私方法。
     - 差分隐私对抗数据中毒，无论对手的目标是什么都提供考虑最坏情况的保护方案，但必须限制对手且必须添加噪声。
   - 防御推断阶段的回避攻击
     - 一个方法：使预测器本身具有差异隐私性，但预测变得随机，也会损害可解释性
     - 更复杂：添加噪音，然后以最高的概率发布预测【需继续研究】

10. 有哪些非恶意故障模式？

    联邦学习特别容易受到来自<u>服务提供商控制之外的不可靠客户端的非恶意故障</u>的影响

    | 类别           | 描述                                                         | 现有方法                                                     |
    | -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | 客户机汇报失败 | 联邦学习中，每轮训练都涉及向客户机广播模型、本地客户机计算和向中央聚合器进行客户机汇报。**如何处理掉队者（出现故障/更慢汇报）**<br />为了提高效率，可能会从通信回合中忽略它们，从而有效地减少参与客户的数量<br />普通联邦学习中使用联邦平均应用模型更新无影响，但使用SecAgg需要考虑故障情况 | ① 在每一轮中选择更多的设备，确保掉队者和失败的设备对整体收敛的影响最小<br />② 复杂：提高SecAgg的效率，缩短客户退出对SecAgg产生不利影响的时间窗口<br />③ 更复杂：开发一个异步版本的SecAgg，不需要客户端在固定的时间段内参与<br />④ 推测：可能会采用在多轮计算中聚合的SecAgg版本 |
    | 数据管道故障   | 联邦学习中的数据管道只存在于每个客户端中，任何联邦学习系统仍然<u>必须定义如何访问原始用户数据并将其预处理为训练数据</u><br />此管道中的错误或意外操作可能会极大地改变联邦学习过程，FL中数据限制使得检测数据管道错误困难 | 使用<u>具有差异隐私的联邦方法训练生成模型</u>，然后使用这些方法<u>合成新的数据样本</u>，这些样本可用于调试底层数据管道 |
    | 带噪模型更新   | 即使不存在攻击者，<u>发送到服务器的模型更新</u>也可能<u>由于网络和体系结构因素而失真</u>，尤其在跨客户端设置中。即使客户端上的数据不是故意恶意的，它也可能具有噪声特征或噪声标签 | ① 使用防御措施来对抗模型更新和数据中毒攻击，但没有明显健壮的方法，不采用<br />② 开发对小到中等水平的噪声具有鲁棒性的训练方法<br />③ 标准联邦训练方法（如联邦平均法）对少量噪声具有内在的鲁棒性 |

11. 隐私和鲁棒性之间的关系？

    - <u>SecAgg安全聚合：确保隐私的一种主要技术工具</u>，用于确保服务器只看到客户机更新的聚合，而不是任何单独的客户机更新。
    - 但<u>SecAgg的使用使得对抗攻击的防御更难实现</u>，因为中央服务器只能看到客户机更新的聚合*【研究如何在使用安全聚合时防御对抗攻击是非常重要的】*
    - <u>SecAgg还为其他防御方法引入了挑战</u>，如许多现有的拜占庭鲁棒聚合方法不知是否与安全聚合兼容

---

> 公平性（略）



## 附录

1. 部分参考了https://github.com/tao-shen/Federated-Learning-FAQ/ 提出的问题和解答

2. 可供参考翻译：https://xwzheng.gitbook.io/fl/

3. 联邦学习有哪些工具和平台？

   - TensorFlow Federated [38]专门针对研究用例，提供大规模模拟功能以及灵活的编排来控制采样。
   - PySyft 是用于安全的私有深度学习Python库。 PySyft使用PyTorch中的联邦学习，差分隐私和多方计算（MPC）将私人数据与模型训练分离。
   - Leaf 提供了多个数据集以及模拟和评估功能。
   - FATE（Federated AI Technology Enabler）是一个开源项目，旨在提供安全的计算框架来支持联邦AI生态系统。
   - PaddleFL 是基于PaddlePaddle 的开源联邦学习框架。在PaddleFL中，通过应用程序演示提供了几种联邦学习策略和训练策略。
   - Clara培训框架包括基于服务器客户端方法和数据隐私保护的跨孤岛联邦学习的支持

4. 联邦学习有什么数据集？

   - EMNIST数据集由671,585个数字图像和大小写英文字符（62个类）组成。 联邦版本将数据集拆分为3,400个不平衡客户端，这些客户端由数字/字符的原始编写者索引。 非IID分布来自每个人独特的写作风格。
   - Stackoverflow数据集由来自Stack Overflow的问答组成，并带有时间戳，分数等元数据。训练数据集拥有342,477多个唯一用户和135,818,730个示例。请注意，时间戳信息可能有助于模拟传入数据的模式。
   - Shakespeare是从The Complete Works of William Shakespeare获得的语言建模数据集。 它由715个字符组成，其连续行是客户端数据集中的示例。训练集有16,068个示例，测试集有2,356个示例。

   - Leafproject 提供了对EMNIST和Shakespeare的预处理，它还提供了sentiment140和celebA数据集的联邦版本。这些数据集具有足够的客户端，可以用于模拟跨设备FL场景，但是对于规模特别重要的问题，它们可能太小。在这方面，Stackoverflow提供了跨设备FL问题的最现实示例。
   - NICO